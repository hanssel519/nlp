{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRPB-PDrhRAu"
   },
   "source": [
    "## Prepare your environment\n",
    "\n",
    "As always, we highly recommend that you use colab, or install all packages with a virtual environment manager, like [venv](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/) or [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html), to prevent version conflicts of different packages.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvbJMhCefPIz"
   },
   "source": [
    "### Install and load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "ng7XkVouhLew",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (1.23.4)\n",
      "Requirement already satisfied: scikit-learn in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: datasets in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (2.6.1)\n",
      "Requirement already satisfied: transformers in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (4.24.0)\n",
      "Requirement already satisfied: torch in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (1.13.0)\n",
      "Requirement already satisfied: sentencepiece in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (0.1.97)\n",
      "Requirement already satisfied: tqdm in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (4.64.1)\n",
      "Requirement already satisfied: jsonlines in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: errant in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (2.3.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: aiohttp in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: xxhash in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (0.10.1)\n",
      "Requirement already satisfied: pandas in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (1.5.1)\n",
      "Requirement already satisfied: packaging in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: multiprocess in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: filelock in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from jsonlines) (22.1.0)\n",
      "Requirement already satisfied: rapidfuzz>=2.0.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from errant) (2.13.6)\n",
      "Requirement already satisfied: spacy<3,>=2.2.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from errant) (2.3.8)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from responses<0.19->datasets) (1.26.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from pandas->datasets) (2022.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: wheel in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99->torch) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99->torch) (44.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<3,>=2.2.0->errant) (2.0.7)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<3,>=2.2.0->errant) (1.0.6)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<3,>=2.2.0->errant) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<3,>=2.2.0->errant) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<3,>=2.2.0->errant) (0.7.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<3,>=2.2.0->errant) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<3,>=2.2.0->errant) (3.0.8)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<3,>=2.2.0->errant) (7.4.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<3,>=2.2.0->errant) (1.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.28.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (44.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.23.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.9)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.10.1)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.64.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.1.1)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/en_core_web_sm -->\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scikit-learn datasets transformers torch sentencepiece tqdm jsonlines errant\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OSdZgl5Vks3n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import jsonlines\n",
    "# from tqdm import tqdm\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rCm_nMBfg5z"
   },
   "source": [
    "## The dataset\n",
    "We are using the W&I+LOCNESS dataset to finetune T5(-small). \n",
    "\n",
    "The W&I+LOCNESS dataset is made up of entries from \n",
    "- Write & Improve (Yannakoudakis et al., 2018), an online web platform that assists non-native English students with their writing, and \n",
    "- the LOCNESS corpus (Granger, 1998), which consists of essays written by native English students.\n",
    "\n",
    "([Details here](https://www.cl.cam.ac.uk/research/nl/bea2019st/) under the title \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oXc9YgL3lJpH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b7f6800c0257d49b\n",
      "Found cached dataset json (/home/nlplab/yhc/.cache/huggingface/datasets/json/default-b7f6800c0257d49b/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 35.53it/s]\n"
     ]
    }
   ],
   "source": [
    "data_files = {'train': os.path.join('data/wi+locness', 'train.jsonl'),\\\n",
    "              'validation': os.path.join('data/wi+locness', 'dev.jsonl')}\n",
    "# ,\\\n",
    "              # 'test': os.path.join('data', 'test.jsonl')}\n",
    "dataset = load_dataset('json', data_files = data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8AWSSF7x9k7Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13778\n",
      "{'text': 'Besides,I find those talking about building massive structures and science interesting and I learnt some knowledge from those programs.', 'corrected': 'Besides, I find those programs talking about building massive structures and science interesting'}\n"
     ]
    }
   ],
   "source": [
    "# have a look!\n",
    "print(len(dataset['train']['text']))\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Besides,I find those talking about building massive structures and science interesting and I learnt some knowledge from those programs.',\n",
       "  'Or maybe she wants smt else?',\n",
       "  \"Everything came us a surprise and you didn't expect that this or that action is just taking place.\"],\n",
       " 'corrected': ['Besides, I find those programs talking about building massive structures and science interesting',\n",
       "  'Or maybe she wants something else?',\n",
       "  \"Everything came us a surprise and you didn't expect that this or that action would   take place.\"]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox-VNFKm9e9X"
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3vmY3GUfrsJ"
   },
   "source": [
    "### Tokenizater\n",
    "Like our previous assignment on sentence classification, we need a tokenizer. This time, we're using T5's tokenizer.\n",
    "\n",
    "- [Tokenizer base class documentation](https://huggingface.co/docs/transformers/v4.24.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer) just FYI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Zw1Mg3qb4iu_"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "I0xXaLQh5EK7"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 't5-small'\n",
    "MODEL_MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TEi0yOjo5gjQ"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    model_max_length=MODEL_MAX_LEN\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVnCzBb3Bo_1"
   },
   "source": [
    "**[ TODO ]:** tokenize the input and output sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xemZbP9ZzwDt"
   },
   "outputs": [],
   "source": [
    "# batch-tokenize inputs \n",
    "def tokenize_batch(batch):\n",
    "    \"\"\" Input: a batch of your dataset\n",
    "        Example: { 'text': [['sentence1'], ['setence2'], ...],\n",
    "                   'corrected': ['correct_sentence1', 'correct_sentence2', ...] }\n",
    "    \"\"\"\n",
    "    \n",
    "    # encode the source sentence, i.e. the grammatically-incorrect sentences\n",
    "    input_sequences = batch['text']\n",
    "    input_encoding = tokenizer(\n",
    "        input_sequences, padding='max_length', max_length=MODEL_MAX_LEN, truncation=True, return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids, attention_mask = input_encoding.input_ids, \\\n",
    "                                input_encoding.attention_mask\n",
    "\n",
    "    # encode the targets, i.e. the corrected sentences\n",
    "    output_sequences = batch['corrected']\n",
    "    target_encoding = tokenizer(\n",
    "        output_sequences, padding='max_length', max_length=MODEL_MAX_LEN, truncation=True, return_tensors='pt'\n",
    "    )\n",
    "    labels = target_encoding.input_ids # we only need the token ids of the target sequences during training\n",
    "\n",
    "    # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    ################################################\n",
    "\n",
    "    \"\"\" Output: a batch of processed dataset\n",
    "        Example: { 'input_ids': ...,\n",
    "                   'attention_masks': ...,\n",
    "                   'label': ... }\n",
    "    \"\"\"\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"label\": labels}\n",
    "    #loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPpjuGZI9vvS"
   },
   "source": [
    "If you look up online tutorials of finetuning T5, you might see that a prefix is added before each sequence before encoding it in the step above. This is done because T5 was originally trained as a multi-task model. Adding a prefix is a way to let the model know which task it should perform with a given text during inference. \n",
    "\n",
    "We don't have to do that here**, because we are only finetuning T5 on a single task, i.e. GEC.\n",
    "\n",
    "\n",
    "For more information, please refer to this [tutorial](https://huggingface.co/docs/transformers/model_doc/t5#training)\n",
    "\n",
    "\n",
    "\n",
    "*** TA's note: In fact, appending a `gec:` prefix to the input sentences during training only worsen the model performance. \n",
    "I learned this the hard way...* ðŸ’” "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjxNMAn0gZuO"
   },
   "source": [
    "### Batch-tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   3, 8500,    6,  196,  253,  273, 2508,   81,  740, 3805, 5278,   11,\n",
      "         2056, 1477,   11,   27,  669,   17,  128, 1103,   45,  273, 1356,    5,\n",
      "            1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 955, 2087,  255, 2746,    3,    7,   51,   17, 1307,   58,    1,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [7462,  764,  178,    3,    9, 4158,   11,   25,  737,   31,   17, 1672,\n",
      "           24,   48,   42,   24, 1041,   19,  131,  838,  286,    5,    1,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'label': tensor([[   3, 8500,    6,   27,  253,  273, 1356, 2508,   81,  740, 3805, 5278,\n",
      "           11, 2056, 1477,    1, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100],\n",
      "        [ 955, 2087,  255, 2746,  424, 1307,   58,    1, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100],\n",
      "        [7462,  764,  178,    3,    9, 4158,   11,   25,  737,   31,   17, 1672,\n",
      "           24,   48,   42,   24, 1041,  133,  240,  286,    5,    1, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100]])}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_batch(dataset[\"train\"][:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sgXO66x_5oFJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/nlplab/yhc/.cache/huggingface/datasets/json/default-b7f6800c0257d49b/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-f1422221c01b0fef.arrow\n",
      "Loading cached processed dataset at /home/nlplab/yhc/.cache/huggingface/datasets/json/default-b7f6800c0257d49b/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-53803bf12c934d6a.arrow\n"
     ]
    }
   ],
   "source": [
    "# map the function to the whole dataset\n",
    "train_val_dataset = dataset.map(tokenize_batch,    # your processing function\n",
    "                                batched = True # Process in batches so it can be faster\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muWZ4iS89qLK"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T57JOJ3zIYs_"
   },
   "source": [
    "### Setup training parameters\n",
    "\n",
    "As before, we use the Trainer API to do the training. You may use the default hyperparameters that the TA has set for you.\n",
    "\n",
    "Document:\n",
    "- [transformers.Seq2SeqTrainingArguments](https://huggingface.co/docs/transformers/master/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments)\n",
    "- [transformers.Seq2SeqTrainer](https://huggingface.co/docs/transformers/master/en/main_classes/trainer#transformers.Seq2SeqTrainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eFiPJ5jwIXLo"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhYRWQCMIdza"
   },
   "source": [
    "### Train ðŸš€\n",
    "\n",
    "This is the easy part. Simply ask the trainer to train the model for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "O2YLnvHT5w9B"
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9547"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HwnlYdfWKY1V"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './model'\n",
    "LEARNING_RATE = 2e-4\n",
    "# BATCH_SIZE = 32\n",
    "BATCH_SIZE=8\n",
    "EPOCH = 5\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir = OUTPUT_DIR,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    per_device_train_batch_size = BATCH_SIZE,\n",
    "    per_device_eval_batch_size = BATCH_SIZE,\n",
    "    num_train_epochs = EPOCH,\n",
    "    # you can set more parameters here if you want\n",
    ")\n",
    "\n",
    "# now give all the information to a trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    # set your parameters here\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_val_dataset[\"train\"],\n",
    "    eval_dataset = train_val_dataset[\"validation\"],\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if any GPU is used\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "id": "YKrOtQRFIc_O",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, corrected. If text, corrected are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13778\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4310\n",
      "  Number of trainable parameters = 60506624\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4310' max='4310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4310/4310 32:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.526400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.459900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.417700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.395800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.378700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.348200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.334100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.333300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./model/checkpoint-500\n",
      "Configuration saved in ./model/checkpoint-500/config.json\n",
      "Model weights saved in ./model/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-500/special_tokens_map.json\n",
      "Copy vocab file to ./model/checkpoint-500/spiece.model\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./model/checkpoint-1000\n",
      "Configuration saved in ./model/checkpoint-1000/config.json\n",
      "Model weights saved in ./model/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-1000/special_tokens_map.json\n",
      "Copy vocab file to ./model/checkpoint-1000/spiece.model\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./model/checkpoint-1500\n",
      "Configuration saved in ./model/checkpoint-1500/config.json\n",
      "Model weights saved in ./model/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-1500/special_tokens_map.json\n",
      "Copy vocab file to ./model/checkpoint-1500/spiece.model\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./model/checkpoint-2000\n",
      "Configuration saved in ./model/checkpoint-2000/config.json\n",
      "Model weights saved in ./model/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-2000/special_tokens_map.json\n",
      "Copy vocab file to ./model/checkpoint-2000/spiece.model\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./model/checkpoint-2500\n",
      "Configuration saved in ./model/checkpoint-2500/config.json\n",
      "Model weights saved in ./model/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-2500/special_tokens_map.json\n",
      "Copy vocab file to ./model/checkpoint-2500/spiece.model\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./model/checkpoint-3000\n",
      "Configuration saved in ./model/checkpoint-3000/config.json\n",
      "Model weights saved in ./model/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-3000/special_tokens_map.json\n",
      "Copy vocab file to ./model/checkpoint-3000/spiece.model\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./model/checkpoint-3500\n",
      "Configuration saved in ./model/checkpoint-3500/config.json\n",
      "Model weights saved in ./model/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-3500/special_tokens_map.json\n",
      "Copy vocab file to ./model/checkpoint-3500/spiece.model\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./model/checkpoint-4000\n",
      "Configuration saved in ./model/checkpoint-4000/config.json\n",
      "Model weights saved in ./model/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-4000/special_tokens_map.json\n",
      "Copy vocab file to ./model/checkpoint-4000/spiece.model\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4310, training_loss=0.3935545370363027, metrics={'train_runtime': 1954.0222, 'train_samples_per_second': 35.255, 'train_steps_per_second': 2.206, 'total_flos': 4661848351703040.0, 'train_loss': 0.3935545370363027, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k4dW8wDIiOJ"
   },
   "source": [
    "### Save for loading during demo\n",
    "\n",
    "**[ TODO ]:** save your model for future use and load it during demo\n",
    "\n",
    "We will ask you to perform inference with your model during demo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "r4CIYw7zIlgU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./model_/config.json\n",
      "Model weights saved in ./model_/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# [ TODO ] save your model for future use\n",
    "# model.save_pretrained('./model_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9xbb4EbInrj"
   },
   "source": [
    "## Prediction\n",
    "Inference is a bit different for a seq2seq model compared to a classification model. \n",
    "\n",
    "The model has to first generate the sequence from the given input sequence. How the sequence is generated differ based on the model. You may read more about it [here](https://huggingface.co/blog/encoder-decoder).\n",
    "\n",
    "Since the generated sequences are represented as vectors / embeddings, we need to *decode* the model output with the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciL3zrcHPLe9",
    "outputId": "6b318492-dda8-44a1-d95a-5500c98bbba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# just to make sure you're using a GPU\n",
    "import torch\n",
    "cur_device = torch.cuda.current_device()\n",
    "device = torch.device(cur_device)\n",
    "print(cur_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true,
    "id": "Rh-WAJuaIqKU",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load finetuned model\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('./model_')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3bh5rO6ItKO"
   },
   "source": [
    "### Get the prediction\n",
    "\n",
    "Here are a few example sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yarsz1A8IvyA",
    "outputId": "87895009-3427-4ff3-c67b-a58619cfa0c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The houses were wonderful.', 'I like working in NYC.', 'She is involved in an accident.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\"The houses was wonderful.\", \"I like to working in NYC.\", \"She is involve in accident.\", ]\n",
    "\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "inputs.to(device)\n",
    "\n",
    "output_sequences = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(output_sequences, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RpYKFkqI7Us"
   },
   "source": [
    "### Predict on the W&I+LOCNESS \"test\" set\n",
    "\n",
    "#### **A note on the \"test\" set**\n",
    "The \"test\" set here is not really the official test set, since the latter is witheld by the dataset provider to ensure fairness among all competitors for SOTA. \n",
    "Instead, the validation set you just used during training is split from the training set, and you'll be evaluating the model on the original validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8rPHqO9AEAZ"
   },
   "source": [
    "**[ TO DO ]:** use the model you just trained to turn the grammatically-incorrect test-set sentences into corrected sentences. This involves **loading** the test set, using the model to **generate** the numerically-represented transformed sentences (in tensor form), and **decoding** the generated tensors. \n",
    "\n",
    "You may reference the [ðŸ¤— documentation](https://huggingface.co/docs/transformers/model_doc/t5#inference) for what to put in the methods.\n",
    "\n",
    "\n",
    "\n",
    "[Optional] (you may do this just for the science; no bonus points will be given for this.) \n",
    "\n",
    "Store the output in the input `dataset` data structure to make life easier if you choose to iterate the output multiple times through the model (see next step for details). Otherwise, save it in any format you find convenient :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7e2e7be957aa41d2\n",
      "Found cached dataset text (/home/nlplab/yhc/.cache/huggingface/datasets/text/default-7e2e7be957aa41d2/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 54.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# load the test data\n",
    "data_files = {'test': os.path.join('data/wi+locness', 'test.txt')}\n",
    "test_data = load_dataset('text', data_files = data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4384\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 's difficult answer at the question \" what are you going to do in the future ? \" if the only one who has to know it is in two minds .\n",
      "['It\\'s a difficult answer at the question \" what are you going to do in']\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"The houses was wonderful.\", \"I like to working in NYC.\", \"She is involve in accident.\", ]\n",
    "sentences = test_data['test'][\"text\"][0]\n",
    "print(sentences)\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "inputs.to(device)\n",
    "\n",
    "output_sequences = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(output_sequences, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sent = dataset['validation'][\"text\"][0]\n",
    "inputs = tokenizer(sent, return_tensors=\"pt\", padding=True)\n",
    "inputs.to(device)\n",
    "\n",
    "print(sent)\n",
    "out = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(out, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kGlUVA7IkhgG"
   },
   "outputs": [],
   "source": [
    "# Implement the functin to generate and batch decoode the generated sequence\n",
    "# batch-tokenize and then decode inputs \n",
    "@torch.no_grad()\n",
    "def decode_batch(batch):\n",
    "    \"\"\" Input: a batch of an **untokenized** dataset\n",
    "        Example: { 'text': ['sentence1', 'setence2', ...],\n",
    "                   'corrected': ['correct_sentence1', 'correct_sentence2', ...] }\n",
    "    \"\"\"\n",
    "    sentences = tokenizer(batch[\"text\"], return_tensors=\"pt\", padding=True)\n",
    "    sentences.to(device)\n",
    "    \n",
    "    \n",
    "    output_sequences = model.generate(\n",
    "        input_ids=sentences[\"input_ids\"],\n",
    "        attention_mask=sentences[\"attention_mask\"],\n",
    "        do_sample=False, \n",
    "    )\n",
    "    \n",
    "    decoded = {}\n",
    "    decoded = {'text': tokenizer.batch_decode(\n",
    "        output_sequences, skip_special_tokens=True\n",
    "    )}\n",
    "    # decoded = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "    # print(decoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "2xO04LGCnjDH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                       | 0/88 [00:00<?, ?ba/s]/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 87/88 [00:16<00:00,  5.32ba/s]\n"
     ]
    }
   ],
   "source": [
    "# adjust the arguments as you need\n",
    "decoded = test_data.map(\n",
    "    decode_batch,    # your processing function\n",
    "    batched = True,  # Process in batches so it can be faster\n",
    "    batch_size=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Zu4Yey5TnBzh"
   },
   "outputs": [],
   "source": [
    "assert len(decoded)==len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ge6su-KyzpZ"
   },
   "source": [
    "[ Optional ] (no bonus points for this)\n",
    "\n",
    "Since some corrections in a sentence may depend on previous corrections, applying GEC sequence tagger only once may not be enough to fully correct the sentence. Thus, many methods suggest running the generated output of a GEC model through the system more than once. Try this on the test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DatasetDict({\n",
       "     test: Dataset({\n",
       "         features: ['text'],\n",
       "         num_rows: 4384\n",
       "     })\n",
       " })]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check on decoded\n",
    "[decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GHOgk9Mn6fCd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 87/88 [00:10<00:00,  8.29ba/s]\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 87/88 [00:10<00:00,  8.17ba/s]\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 87/88 [00:10<00:00,  8.37ba/s]\n"
     ]
    }
   ],
   "source": [
    "iterations = 3\n",
    "pred_iter = [decoded] # you may want to save the output of each iteration\n",
    "\n",
    "for i in range(iterations):\n",
    "    decoded = pred_iter[i].map(\n",
    "        decode_batch,    # your processing function\n",
    "        batched = True,  # Process in batches so it can be faster\n",
    "        batch_size=50\n",
    "        )\n",
    "    \n",
    "    pred_iter.append(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('It\\'s a difficult answer at the question \" what are you going to do in',\n",
       " 'It\\'s a difficult answer to the question \" what are you going to do in the',\n",
       " 'It\\'s a difficult answer to the question \" what are you going to do in the',\n",
       " 'It\\'s a difficult answer to the question \" what are you going to do in the')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_iter[0]['test']['text'][0], pred_iter[1]['test']['text'][0],pred_iter[2]['test']['text'][0], pred_iter[3]['test']['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDZ0lZ6bz7Q0"
   },
   "source": [
    "[ Optional ] (no bonus points) Write a script to view the differences between each iteration, and view the results to decide which iteration you want to evaluate on. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "I8KWNiP6zAVD"
   },
   "source": [
    "diffs = []\n",
    "for idx, it in enumerate(pred_iter):\n",
    "    i = 0\n",
    "    print(f\"ITERATION {idx}\")\n",
    "    for txt_idx, text in enumerate(it['text']):\n",
    "        ...\n",
    "    print(f\"NUM CORRECTED SENTENCES: {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_8v76PZ0LcO"
   },
   "source": [
    "## Evaluation\n",
    "#### ERRANT\n",
    "One evaluation metric for GEC is the ERRANT (see details under the title [Evaluation](https://www.cl.cam.ac.uk/research/nl/bea2019st/)), an improved version of the [MaxMatch scorer](https://github.com/nusnlp/m2scorer), where precision and recall are based on span and token match.\n",
    "\n",
    "The metric ERRANT uses is [F0.5](https://en.wikipedia.org/wiki/F-score#F%CE%B2_score), where precision is weighted twice the recall.\n",
    "\n",
    "We use [the ERRANT toolkit](https://github.com/chrisjbryant/errant) to evaluate our output. \n",
    "\n",
    "== a couple of terms ==\n",
    "- Sources = the sentences to be corrected\n",
    "- Hypotheses = the sentences we predicted, hopefully grammatically correct\n",
    "- References = the gold-standard sentences (i.e. sentences grammatically corrected by human annotators; the \"answer\")\n",
    "\n",
    "\n",
    "`errant_parallel` converts the span-based difference between the **sources** and the **hypotheses** into a `.m2` file.\n",
    "\n",
    "```\n",
    "S It 's difficult answer at the question \" what are you going to do in the future ? \" if the only one who has to know it is in two minds .\n",
    "A 3 3|||M:VERB:FORM|||to|||REQUIRED|||-NONE-|||0\n",
    "A 4 5|||U:PREP||||||REQUIRED|||-NONE-|||0\n",
    "```\n",
    "\n",
    "Next, `errant_compare` compares the above `.m2` file against the `.m2` file of a **reference** and the **source**, and calculates the F0.5 score. \n",
    "\n",
    "If you feel like you need to draw a graph to understanding this more clearly, it's okay. The TA did too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1255Pk7DN6He"
   },
   "source": [
    "**[ TO DO ]** Use the ERRANT scorer to evaluate the test set and show the results\n",
    "...you don't really need to do anything here. Just run the code (perhaps change the outptu file name) and show the results during demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPATH='evaluation'\n",
    "OUTNAME='evaluation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "qHkz27v6KwQg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p \"evaluation\"\n",
    "!touch \"evaluation/evaluation.out\" # change the output file path and name as you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "eRHRwXAGKHSN"
   },
   "outputs": [],
   "source": [
    "with open(\"evaluation/evaluation.out\", \"w\") as f:\n",
    "    for line in pred_iter[1]['test']['text']:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcUhFg_Q6zAy",
    "outputId": "2659dbd4-c9f6-4ecd-944e-10f8409d6068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Loading resources...\n",
      "Processing parallel files...\n"
     ]
    }
   ],
   "source": [
    "# this will take about 1 minute\n",
    "!errant_parallel -ori data/wi+locness/test.txt -cor evaluation/evaluation.out -out evaluation/evaluation.m2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WT7GOZbwK-Yx",
    "outputId": "ed250072-dc8c-4a0e-ac24-035c9c1f0db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "899\t9495\t6562\t0.0865\t0.1205\t0.0917\n",
      "==============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!errant_compare -ref data/wi+locness/bea-full-valid.m2 -hyp evaluation/evaluation.m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIAODr-340zM"
   },
   "source": [
    "You may notice that the scores are quite low. This is fine. (The TA got only ~0.1 F0.5 ðŸ˜…)\n",
    "\n",
    "This (finetuning T5 by feeding it parallel text) is only one of the [many methods](https://nlpprogress.com/english/grammatical_error_correction.html) developed in attempt to solve GEC. Other contributing factors for this include:\n",
    "- this T5 is tiny (60m parameters) compared to other T5s (e.g. T5-base: 220m, T5-large: 770m);\n",
    "- the training data is quite small. Studies usually combine many other datasets, such as Lang-8 (947k sentences), FEC (34k sentences), and perform data augmentation.\n",
    "\n",
    "**What other factors can you think of that contribute to the low performance?**\n",
    "\n",
    "**[ TO DO (Optional, with bonus points) ]:** Think of one factor that might affect the model performance, and \n",
    "\n",
    "(a) come up with 1 way to verify that via experimentation (you don't need to actually do the experiment), OR \n",
    "\n",
    "(b) find 1 paper to prove your hypothesis. We will ask you to show the paper and point out the part where it proves your hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr1xZuNgK7ky"
   },
   "source": [
    "----------\n",
    "**[ TO DO ]** Plot a histogram of the `.m2` file you generated.\n",
    "\n",
    "You now have the gold standard `.m2` file and the `.m2` file from the corrections you generated from T5. \n",
    "\n",
    "In the `.m2` files, lines containing items seperated by 3 pipes (|||) are the correction types (and spans for their corresponding words or phrases) generated by comparing the sentences from the source file and the source/hypotheses file. \n",
    "\n",
    "For example, for `A 3 3|||M:VERB:FORM|||to|||REQUIRED|||-NONE-|||0`, `M:VERB:FORM` is the correction type.\n",
    "\n",
    "Below is a bar plot (histogram) of the correction types from the gold-standard `.m2` file (i.e.`bea-full-valid.m2`). Plot **a histogram/bar plot for the top-10 correction types** of the `.m2` file generated by **the source and the hypothesis**. How are the top-10 corrections different from the gold-standard ones?\n",
    "![fqLtmi0.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "S It 's difficult answer at the question \" what are you going to do in the future ? \" if the only one who has to know it is in two minds .\n",
      "A 0 1|||R:OTHER|||It's|||REQUIRED|||-NONE-|||0\n",
      "A 1 2|||R:OTHER|||a|||REQUIRED|||-NONE-|||0\n",
      "A 4 5|||R:PREP|||to|||REQUIRED|||-NONE-|||0\n",
      "A 15 20|||U:OTHER||||||REQUIRED|||-NONE-|||0\n",
      "A 21 33|||U:OTHER||||||REQUIRED|||-NONE-|||0\n",
      "\n",
      "S When I was younger I used to say that I wanted to be a teacher , a saleswoman and even a butcher .. I do n't know why .\n",
      "A 3 4|||R:OTHER|||younger,|||REQUIRED|||-NONE-|||0\n",
      "A 14 16|||R:ORTH|||teacher,|||REQUIRED|||-NONE-|||0\n"
     ]
    }
   ],
   "source": [
    "! head -10 evaluation/evaluation.m2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test\n",
    "test_str = \"A 0 1|||R:OTHER|||It's|||REQUIRED|||-NONE-|||0\"\n",
    "result = re.findall(r'[|||](\\w+):(\\w+)[|||]', test_str)\n",
    "print(result)\n",
    "print(result[0][0], result[0][1])\n",
    "a = result[0][0]+':'+result[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#æ‰¾|||è·Ÿ|||ä¹‹é–“\n",
    "with open('evaluation/evaluation.m2') as f:\n",
    "    for line in f:\n",
    "        # print(line)\n",
    "        result = re.findall(r'[|||](\\w+):(\\w+)[|||]', line)\n",
    "        # print(result)\n",
    "        if not result:\n",
    "            continue\n",
    "        a = result[0][0]+':'+result[0][1]\n",
    "        if a not in counters:\n",
    "            counters[a] = 1\n",
    "        else:\n",
    "            counters[a]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R:OTHER': 1001,\n",
       " 'R:PREP': 169,\n",
       " 'U:OTHER': 2069,\n",
       " 'R:ORTH': 4828,\n",
       " 'U:PUNCT': 316,\n",
       " 'U:DET': 168,\n",
       " 'R:NOUN': 383,\n",
       " 'U:PREP': 62,\n",
       " 'U:PRON': 19,\n",
       " 'R:PRON': 16,\n",
       " 'M:OTHER': 28,\n",
       " 'R:VERB': 84,\n",
       " 'R:DET': 24,\n",
       " 'M:DET': 193,\n",
       " 'M:PREP': 49,\n",
       " 'R:MORPH': 66,\n",
       " 'R:PART': 17,\n",
       " 'U:CONJ': 8,\n",
       " 'U:VERB': 35,\n",
       " 'R:ADJ': 33,\n",
       " 'R:SPELL': 136,\n",
       " 'R:ADV': 16,\n",
       " 'M:VERB': 14,\n",
       " 'R:WO': 32,\n",
       " 'U:NOUN': 20,\n",
       " 'R:CONTR': 18,\n",
       " 'M:PRON': 26,\n",
       " 'U:ADV': 25,\n",
       " 'M:ADV': 3,\n",
       " 'U:ADJ': 10,\n",
       " 'M:CONJ': 4,\n",
       " 'M:NOUN': 12,\n",
       " 'R:PUNCT': 8,\n",
       " 'U:CONTR': 3,\n",
       " 'M:ADJ': 3,\n",
       " 'M:PART': 1,\n",
       " 'U:PART': 2,\n",
       " 'M:PUNCT': 1}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M:PART', 1),\n",
       " ('M:PUNCT', 1),\n",
       " ('U:PART', 2),\n",
       " ('M:ADV', 3),\n",
       " ('U:CONTR', 3),\n",
       " ('M:ADJ', 3),\n",
       " ('M:CONJ', 4),\n",
       " ('U:CONJ', 8),\n",
       " ('R:PUNCT', 8),\n",
       " ('U:ADJ', 10),\n",
       " ('M:NOUN', 12),\n",
       " ('M:VERB', 14),\n",
       " ('R:PRON', 16),\n",
       " ('R:ADV', 16),\n",
       " ('R:PART', 17),\n",
       " ('R:CONTR', 18),\n",
       " ('U:PRON', 19),\n",
       " ('U:NOUN', 20),\n",
       " ('R:DET', 24),\n",
       " ('U:ADV', 25),\n",
       " ('M:PRON', 26),\n",
       " ('M:OTHER', 28),\n",
       " ('R:WO', 32),\n",
       " ('R:ADJ', 33),\n",
       " ('U:VERB', 35),\n",
       " ('M:PREP', 49),\n",
       " ('U:PREP', 62),\n",
       " ('R:MORPH', 66),\n",
       " ('R:VERB', 84),\n",
       " ('R:SPELL', 136),\n",
       " ('U:DET', 168),\n",
       " ('R:PREP', 169),\n",
       " ('M:DET', 193),\n",
       " ('U:PUNCT', 316),\n",
       " ('R:NOUN', 383),\n",
       " ('R:OTHER', 1001),\n",
       " ('U:OTHER', 2069),\n",
       " ('R:ORTH', 4828)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sorted_data = sorted(counters.items(), key=lambda i: i[1], reverse=True)\n",
    "sorted_data_10 = sorted_data[:10]        # æ°´å¹³è³‡æ–™é»ž\n",
    "x = [ seq[0] for seq in sorted_data_10 ]\n",
    "h = [ seq[1] for seq in sorted_data_10 ]   # é«˜åº¦\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.bar(x,h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0y_pRWKb2aUh"
   },
   "source": [
    "### Evaluation: Your turn\n",
    "You have two main tasks:\n",
    "1. **[TO DO]** Evaluate the model we just trained with ERRANT on another dataset: [JFLEG](https://github.com/keisks/jfleg). (Do you get a higher or lower score? Explain.)\n",
    "2. **[TO DO]** GLEU is another metric, originally developed to evaluate machine translation, that is used to evaluate GEC. Use GLEU to evaluate your model on **both** W&I+LOCNESS and JFLEG. \n",
    "\n",
    "You may reference [this](https://www.nltk.org/api/nltk.translate.gleu_score.html) or [this](https://github.com/keisks/jfleg/blob/master/eval/gleu.py) to calculate the GLEU scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sG0TROElO2bU"
   },
   "source": [
    "### Evaluate on JFLEG with ERRANT\n",
    "Note: For JFLEG, you need to generate your own gold-standard `.m2` file. Use `errant_parallel` like you did for generating the source-hypothesis `.m2` file.\n",
    "\n",
    "JFLEG provides multiple reference files. For simplicity, just use `dev.ref0` as the reference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "KIjGYjzPPEIz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-28d7b9689b0841b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default to /home/nlplab/yhc/.cache/huggingface/datasets/text/default-28d7b9689b0841b3/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3615.78it/s]\n",
      "Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 232.81it/s]\n",
      "                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/nlplab/yhc/.cache/huggingface/datasets/text/default-28d7b9689b0841b3/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 335.14it/s]\n"
     ]
    }
   ],
   "source": [
    "jf_test_data = load_dataset(\n",
    "    'text', data_files = os.path.join('data/jfleg', 'dev.src')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## å¯«åˆ°é€™å–”ï½žï½ž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "ZGh5tytOPSOL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 15/16 [00:02<00:00,  5.35ba/s]\n"
     ]
    }
   ],
   "source": [
    "jf_decoded = jf_test_data.map(\n",
    "    decode_batch,    # your processing function\n",
    "    batched = True,  # Process in batches so it can be faster\n",
    "    batch_size=50\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 754\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jf_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "Tf8fZqwsQThG"
   },
   "outputs": [],
   "source": [
    "# write to file for evaluation\n",
    "with open(\"evaluation/evaluation_jfleg.FILE\", \"w\") as f:\n",
    "    for line in jf_decoded['train']['text']:\n",
    "        f.write(line+\"\\n\")\n",
    "# with open(\"evaluation/evaluation.out\", \"w\") as f:\n",
    "#     for line in pred_iter[1]['test']['text']:\n",
    "#         f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "4cdqAdoFRS6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Loading resources...\n",
      "Processing parallel files...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Loading resources...\n",
      "Processing parallel files...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "309\t1799\t2391\t0.1466\t0.1144\t0.1388\n",
      "==============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ERRANT-evaluate JFLEG\n",
    "# ref0, 1,2,3æ­£ç¢ºç­”æ¡ˆ\n",
    "\n",
    "!errant_parallel -ori data/jfleg/dev.src -cor evaluation/evaluation_jfleg.FILE -out evaluation/evaluation_jfleg.m2\n",
    "!errant_parallel -ori data/jfleg/dev.src -cor data/jfleg/dev.ref0 -out outputs/jfleg/ref0.m2\n",
    "!errant_compare -ref outputs/jfleg/ref0.m2 -hyp evaluation/evaluation_jfleg.m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN_3I-WtR_mw"
   },
   "source": [
    "### GLEU evaluation for WI+LOC and JFLEG\n",
    "Note: the GLEU calculator may offter sentence-based GLEU scores and the mean GLEU score. You only need to obtain the mean GLEU score for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "8VeKrF2ZBgxT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Running GLEU...\n",
      "evaluation/evaluation.out\n",
      "There is one reference. NOTE: GLEU is not computing the confidence interval.\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py:2343: RuntimeWarning: invalid value encountered in multiply\n",
      "  lower_bound = _a * scale + loc\n",
      "/home/nlplab/yhc/env/nlp_hw/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py:2344: RuntimeWarning: invalid value encountered in multiply\n",
      "  upper_bound = _b * scale + loc\n",
      "0.331052\n"
     ]
    }
   ],
   "source": [
    "from GLEU import GLEU\n",
    "\n",
    "# WI+LOC\n",
    "# !errant_parallel -ori data/wi+locness/test.txt -cor evaluation/evaluation.out -out evaluation/evaluation.m2\n",
    "\n",
    "! python gleu.py  -r data/wi+locness/reference.txt -s data/wi+locness/test.txt --hyp evaluation/evaluation.out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n6T3jEjI0lE"
   },
   "source": [
    "**[ TO DO (Optional, with bonus points) ]** Is GLEU or ERRANT higher? Which of these is a better measure of grammaticity? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Running GLEU...\n",
      "evaluation/evaluation_jfleg.FILE\n",
      "[['0.268308', '0.004422', '(0.260,0.277)']]\n"
     ]
    }
   ],
   "source": [
    "# ref/: my_reference[0-3].txt\n",
    "! python gleu.py  -r data/jfleg/dev.ref[0-3] -s data/jfleg/dev.src --hyp evaluation/evaluation_jfleg.FILE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCduvhDfJF8u"
   },
   "source": [
    "## TA's Note\n",
    "\n",
    "Phew, you made it to the end of the tutorial! Make sure you make an appointment to show your work and turn in your finished assignment before next week's lesson. Don't worry if you didn't pass the evaluation requirements, you'll still get partial points for trying. \n",
    "\n",
    "Grading:\n",
    "- Optional TODOs are bonus points. \n",
    "- You will earn 90 points from completing the non-optional TODOs."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

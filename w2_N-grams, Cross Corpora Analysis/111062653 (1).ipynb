{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVPIBjwjx6pO"
   },
   "source": [
    "# Word Count, Phrase Analysis, Cross-Corpus Analysis\n",
    "\n",
    "In learning English, there are phrases and words that are overly used and seldom used - it depends on what corpus is being used. Here, we will do word count, phrase analysis and cross-corpus analysis to determine the phrases that are overly used by learners.\n",
    "<br><br>\n",
    "One dataset is taken from [`British National Corpus`](http://www.natcorp.ox.ac.uk/), which is from 100 million word collection of samples of written and spoken language from a wide range of sources, designed to represent a wide cross-section of British English, both spoken and written, from the late twentieth century. Another one is called [`NAIST Lang-8`](https://sites.google.com/site/naistlang8corpora/),a language exchange social networking website geared towards language learners. The website is run by Lang-8 Inc., which is based in Tokyo, Japan.\n",
    "\n",
    "\n",
    "https://drive.google.com/drive/folders/1vtCjRptZL6T4mffzbnqwi5i4WrqVnZHr?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xotpb7p5x6pd"
   },
   "source": [
    "## N-gram counting\n",
    "We will do tokenization and calculation of frequency. The rules of tokenization in this Lab are:\n",
    " 1. Ignore case (e.g., \"The\" is the same as \"the\")\n",
    " 2. Split by white spaces <s>and punctuations</s>\n",
    " 3. Ignore all punctuation\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GC_wab2p2Pam"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8iLjwEwBx6ph"
   },
   "outputs": [],
   "source": [
    "a_string = '!hi. wh?at is the weat[h]er lik?e.'\n",
    "new_string = re.sub(r'[^\\w\\s]', '', a_string)\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    \"This is an example.'\n",
    "\n",
    "    Sample output: \n",
    "    ['this', 'is', 'an', 'example', '.']\n",
    "    \"\"\"  \n",
    "    #### [ TODO ] transform text to lower case\n",
    "    text = text.lower()\n",
    "    #### [ TODO ] seperate the words by white space\n",
    "    # Use .translate() for the fastest performance\n",
    "        # print(string.punctuation)\n",
    "        # Returns: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    text = re.sub(r'[0-9]', \" \", text)\n",
    "    #tokens = text.split()\n",
    "    \n",
    "    tokens = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    return tokens\n",
    "    \n",
    "from collections import Counter\n",
    "\n",
    "def calculate_frequency(tokens):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    ['this', 'is', 'an', 'example', ...]\n",
    "\n",
    "    Sample output: \n",
    "    {\n",
    "        'the': 79809, \n",
    "        'project': 288,\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    #### [ TODO ] \n",
    "    fre = Counter(tokens)\n",
    "    return fre\n",
    "\n",
    "# 回傳\n",
    "def get_ngram(tokens, n=2):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    ['this', 'is', 'an', 'example', ...]\n",
    "\n",
    "    Sample output: \n",
    "    ['this is', 'is an', 'an example', ...]\n",
    "    \"\"\"\n",
    "    #### [TODO] \n",
    "    return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-1)]\n",
    "#     ngram = []\n",
    "#     for i in range(len(tokens)-1):\n",
    "#         ngram.append(tokens[i:i+n])\n",
    "#     return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['factsheet', 'what', 'is', 'aids', 'aids', 'immune', 'deficiency', 'syndrome', 'is', 'a', 'condition', 'caused', 'by', 'a', 'virus', 'called', 'hiv', 'immuno', 'deficiency', 'virus', 'this', 'virus', 'affects', 'the', 'body', 's', 'defence', 'system', 'so', 'that', 'it', 'can', 'not', 'fight', 'infection', 'how', 'is', 'infection', 'through', 'unprotected', 'sexual', 'intercourse', 'with', 'an', 'infected', 'partner', 'through', 'infected', 'blood', 'or', 'blood', 'products', 'from', 'an', 'infected', 'mother', 'to', 'her', 'baby', 'it', 'is', 'not', 'transmitted', 'from', 'giving', 'bloodmosquito', 'bitestoilet', 'seatskissingfrom', 'normal', 'daytoday', 'contact', 'how', 'does', 'it', 'affect', 'you', 'the', 'medical', 'aspects', 'can', 'be', 'cancer', 'pneumonia', 'sudden', 'blindness', 'dementia', 'dramatic', 'weight', 'loss', 'or', 'any', 'combination', 'of', 'these', 'often', 'people', 'are', 'rejected', 'by', 'family', 'and', 'friends', 'leaving', 'them', 'to', 'face', 'this', 'chronic', 'condition', 'did', 'you', 'know', 'there', 'is', 'no', 'vaccine', 'or', 'currently', 'available', 'million', 'people', 'worldwide', 'are', 'infected', 'with', 'hiv', 'you', 'can', 'be', 'infected', 'for', 'between', 'years', 'without', 'realising', 'it', 'out', 'of', 'people', 'are', 'heterosexual', 'women', 'are', 'twice', 'as', 'at', 'risk', 'from', 'infection', 'as', 'men', 'infections', 'it', 'is', 'probable', 'that', 'there', 'are', 'between', 'people', 'actually', 'there', 'are', 'nearly', 'cases', 'of', 'aids', 'of', 'which', 'nearly', 'have', 'already', 'died']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factsheet': 1, 'what': 1, 'is': 6, 'aids': 3, 'immune': 1, 'deficiency': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join('data', 'test.txt')\n",
    "BNC_unigram = []\n",
    "#BNC_unigram_counter = Counter()\n",
    "#### [ TODO ] generate BNC unigrams and calculate document frequency of unigram in BNC\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        tokens = tokenize(line)\n",
    "        BNC_unigram.extend(tokens)\n",
    "print(BNC_unigram)\n",
    "BNC_unigram_counter = calculate_frequency(BNC_unigram)\n",
    "\n",
    "dict(list(BNC_unigram_counter.items())[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Sj3-ZuWP2Pao"
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join('data', 'bnc.txt')\n",
    "BNC_unigram = []\n",
    "#BNC_unigram_counter = Counter()\n",
    "#### [ TODO ] generate BNC unigrams and calculate document frequency of unigram in BNC\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        tokens = tokenize(line)\n",
    "        BNC_unigram.extend(tokens)\n",
    "BNC_unigram_counter = calculate_frequency(BNC_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factsheet': 59,\n",
       " 'what': 196659,\n",
       " 'is': 791567,\n",
       " 'aids': 2521,\n",
       " 'immune': 748,\n",
       " 'deficiency': 531,\n",
       " 'syndrome': 931,\n",
       " 'a': 1687867,\n",
       " 'condition': 6180,\n",
       " 'caused': 6332,\n",
       " 'by': 364833,\n",
       " 'virus': 1199,\n",
       " 'called': 22822,\n",
       " 'hiv': 1570,\n",
       " 'immuno': 5,\n",
       " 'this': 367307,\n",
       " 'affects': 1107,\n",
       " 'the': 4546697,\n",
       " 'body': 19093,\n",
       " 's': 678803}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(BNC_unigram_counter.items())[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eZlkiCuQx6pt"
   },
   "outputs": [],
   "source": [
    "# Read lang-8 Data\n",
    "file_path = os.path.join('data','lang8.txt')\n",
    "lang_unigram = []\n",
    "#lang_unigram_counter = Counter()\n",
    "\n",
    "#### [ TODO ] generate lang8 unigrams and calculate document frequency of unigram in lang8\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        tokens = tokenize(line)\n",
    "        lang_unigram.extend(tokens)\n",
    "lang_unigram_counter = calculate_frequency(lang_unigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPBceKOax6pt"
   },
   "source": [
    "## Rank\n",
    "Rank unigrms by their frequencies. The higher the frequency, the higher the rank. (The most frequent unigram ranks 1.)<br>\n",
    "<span style=\"color: red\">[ TODO ]</span> <u>Rank unigrams for Lang-8 and BNC.</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SH9xlXpBx6pu"
   },
   "outputs": [],
   "source": [
    "lang_unigram_Rank = {}\n",
    "\n",
    "#### [ TODO ] Rank unigrams for lang\n",
    "\n",
    "#sort 与 sorted 区别：\n",
    "#sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作。\n",
    "#list 的 sort 方法返回的是对已经存在的列表进行操作，无返回值，而内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。\n",
    "# 用value排序，由大到小所以reverse\n",
    "# type(sorted): list\n",
    "for i, unigram in enumerate(sorted(lang_unigram_counter.items(), key=lambda item: item[1], reverse=True)):\n",
    "    # unigram = [{'a': 10}, {'b': 100}, {'c'; 20}..]\n",
    "    # RATIO 用dictionary不用包兩層回圈, 用list就要\n",
    "    lang_unigram_Rank[unigram[0]]= i+1\n",
    "    #lang_unigram_Rank.append((unigram[0], i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'to': 3,\n",
       " 'and': 4,\n",
       " 'in': 5,\n",
       " 'a': 6,\n",
       " 'is': 7,\n",
       " 'that': 8,\n",
       " 'as': 9,\n",
       " 'be': 10,\n",
       " 'for': 11,\n",
       " 'this': 12,\n",
       " 'it': 13,\n",
       " 'are': 14,\n",
       " 'with': 15,\n",
       " 'by': 16,\n",
       " 'on': 17,\n",
       " 'was': 18,\n",
       " 'not': 19,\n",
       " 'from': 20}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(lang_unigram_Rank.items())[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rN3MQTebx6pv"
   },
   "outputs": [],
   "source": [
    "BNC_unigram_Rank = {}\n",
    "\n",
    "#### [ TODO ] Rank unigrams for BNC\n",
    "for i, unigram in enumerate(sorted(BNC_unigram_counter.items(), key=lambda item: item[1], reverse=True)):\n",
    "    # unigram = [{'a': 10}, {'b': 100}, {'c'; 20}..]\n",
    "    BNC_unigram_Rank[unigram[0]]= i+1\n",
    "    #BNC_unigram_Rank.append((unigram[0], i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'to': 3,\n",
       " 'and': 4,\n",
       " 'a': 5,\n",
       " 'in': 6,\n",
       " 'it': 7,\n",
       " 'is': 8,\n",
       " 'i': 9,\n",
       " 'that': 10,\n",
       " 'was': 11,\n",
       " 's': 12,\n",
       " 'for': 13,\n",
       " 'you': 14,\n",
       " 'he': 15,\n",
       " 'with': 16,\n",
       " 'on': 17,\n",
       " 'be': 18,\n",
       " 'as': 19,\n",
       " 'at': 20}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(BNC_unigram_Rank.items())[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pm26VfkDx6pv"
   },
   "source": [
    "## Calculate Rank Ratio\n",
    "In this step, you need to map the same unigram in two dataset, and calculate the Rank Ratio of unigrams.  <br>Please follow the formula for calculating Rank Ratio:<br> \n",
    "<br>\n",
    "\n",
    "$Rank Ratio = \\frac{Rank of BNC }{Rank of Lang8}$\n",
    "<br><br>\n",
    "If the unigram doesn't appear in BNC, the rank of it is treated as 1.\n",
    "\n",
    "<span style=\"color: red\">[ TODO ]</span> Please calculate all rank ratios of unigrams in Lang-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kNSj6gbU2Paq"
   },
   "outputs": [],
   "source": [
    "#### [ TODO ] Calculate Rank Ratio\n",
    "# lang_unigram_Rank = {\n",
    "#     'a' = 1,\n",
    "#     'b' = 2,\n",
    "#     'c' = 3\n",
    "# }\n",
    "rank_ratio = {}\n",
    "for word,rank in lang_unigram_Rank.items():\n",
    "    #if word in BNC_unigram_Rank.keys():\n",
    "    rank_ratio[word] = (BNC_unigram_Rank[word]/rank) if word in BNC_unigram_Rank.keys() else (1/rank)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U08oh2Ex6pw"
   },
   "source": [
    "## sort the result\n",
    "<span style=\"color: red\">[ TODO ]</span> Please show top 30 unigrams in Rank Ratio and the value of their Rank Ratio in this format: \n",
    "<br>\n",
    "<img src=\"https://scontent-hkt1-2.xx.fbcdn.net/v/t39.30808-6/307940624_756082125461769_4218487831464443689_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=730e14&_nc_ohc=M0u8b1s2wakAX_Mgt7E&_nc_ht=scontent-hkt1-2.xx&oh=00_AT_peeQy_D2UyQYlMWbCIZjQTU7F38SJyE2A09J_SnZ-aA&oe=632E03C0\" width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MhyGW1jC2Paq",
    "outputId": "f3c349ba-6859-4d68-dff8-4e02d3846c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank\tunigram\t\t\t\tRank Ratio\n",
      "1\tdoesnt\t\t\t85.345\n",
      "2\tinternet\t\t\t72.549\n",
      "3\tcountrys\t\t\t69.447\n",
      "4\topcit\t\t\t51.871\n",
      "5\tradstone\t\t\t50.14\n",
      "6\tisnt\t\t\t49.776\n",
      "7\tuht\t\t\t49.671\n",
      "8\teu\t\t\t49.394\n",
      "9\tkants\t\t\t48.977\n",
      "10\tdont\t\t\t48.567\n",
      "11\tcompanys\t\t\t48.271\n",
      "12\tanthocyanins\t\t\t47.487\n",
      "13\tibid\t\t\t43.74\n",
      "14\tjapans\t\t\t43.387\n",
      "15\twebers\t\t\t43.054\n",
      "16\tluthers\t\t\t41.95\n",
      "17\tbryman\t\t\t40.181\n",
      "18\tmpa\t\t\t39.377\n",
      "19\tibidp\t\t\t39.355\n",
      "20\twomens\t\t\t38.4\n",
      "21\tcreon\t\t\t37.971\n",
      "22\tmicroneedles\t\t\t37.212\n",
      "23\trtas\t\t\t37.145\n",
      "24\tdidnt\t\t\t36.673\n",
      "25\tpneumophila\t\t\t35.763\n",
      "26\tglobalisation\t\t\t35.704\n",
      "27\troosevelts\t\t\t35.474\n",
      "28\tpunic\t\t\t34.983\n",
      "29\tmanydown\t\t\t34.947\n",
      "30\tchinas\t\t\t34.85\n"
     ]
    }
   ],
   "source": [
    "#### [ TODO ] \n",
    "# sorted(iterable, cmp=None, key=None, reverse=False)\n",
    "# rank_ratio is a dictionary \n",
    "print(f'rank\\tunigram\\t\\t\\t\\tRank Ratio')\n",
    "for i,ratio_set in enumerate(sorted(rank_ratio.items(), key=lambda item: item[1],reverse=True)[:30]):\n",
    "    print(f'{i+1}\\t{ratio_set[0]}\\t\\t\\t{round(ratio_set[1],3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOllPQ9-x6px"
   },
   "source": [
    "## for Bigrams\n",
    "<span style=\"color: red\">[ TODO ]</span> Do the Same Thing for Bigrams  \n",
    "Hint:  \n",
    "1. generate all bigrams for BNC / lang8  \n",
    "2. calculate frequency for each bigrams  \n",
    "3. rank bigrams by frequency  \n",
    "4. calculate the rank ratio of each bigram\n",
    "5. print out the top 30 highest rank ratio bigrams  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zNR5m63D8Zf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factsheet what': 1,\n",
       " 'what is': 13278,\n",
       " 'is aids': 13,\n",
       " 'aids immune': 10,\n",
       " 'immune deficiency': 29,\n",
       " 'deficiency syndrome': 16}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### [ TODO ] \n",
    "# generate all bigrams for BNC\n",
    "# calculate frequency for each bigrams\n",
    "\n",
    "file_path = os.path.join('data', 'bnc.txt')\n",
    "BNC_bigram = []\n",
    "#BNC_bigram_counter = Counter()\n",
    "#### [ TODO ] generate BNC bigrams and calculate document frequency of bigram in BNC\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        tokens = tokenize(line)\n",
    "        bigram = get_ngram(tokens, n=2)\n",
    "        BNC_bigram.extend(bigram)\n",
    "BNC_bigram_counter = calculate_frequency(BNC_bigram)\n",
    "\n",
    "dict(list(BNC_bigram_counter.items())[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'having spent': 3,\n",
       " 'spent half': 1,\n",
       " 'half days': 1,\n",
       " 'days and': 47,\n",
       " 'and full': 23,\n",
       " 'full weeks': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### [ TODO ] \n",
    "# generate all bigrams for lang8\n",
    "# calculate frequency for each bigrams\n",
    "file_path = os.path.join('data','lang8.txt')\n",
    "lang_bigram = []\n",
    "#lang_bigram_counter = Counter()\n",
    "\n",
    "#### [ TODO ] generate lang8 bigrams and calculate document frequency of bigram in lang8\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        tokens = tokenize(line)\n",
    "        # get_ngram return a list\n",
    "        bigram = get_ngram(tokens, n=2)\n",
    "        lang_bigram.extend(bigram)\n",
    "lang_bigram_counter = calculate_frequency(lang_bigram)\n",
    "\n",
    "dict(list(lang_bigram_counter.items())[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xjBx-rcU2Par",
    "outputId": "d9da3005-d9bf-4af1-b045-def8bfde6194"
   },
   "outputs": [],
   "source": [
    "#### [ TODO ]  rank bigrams by frequency\n",
    "BNC_bigram_Rank = {}\n",
    "for i,bigram in enumerate(sorted(BNC_bigram_counter.items(), key=lambda item: item[1],reverse=True)):\n",
    "    BNC_bigram_Rank[bigram[0]] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [ TODO ] rank bigrams by frequency\n",
    "lang_bigram_Rank = {}\n",
    "for i,bigram in enumerate(sorted(lang_bigram_counter.items(), key=lambda item: item[1],reverse=True)):\n",
    "    lang_bigram_Rank[bigram[0]] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_rank_ratio = {}\n",
    "for word,rank in lang_bigram_Rank.items():\n",
    "    #if word in BNC_bigram_Rank.keys():\n",
    "    bi_rank_ratio[word] = (BNC_bigram_Rank[word]/rank) if word in BNC_bigram_Rank.keys() else (1/rank)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank\tbigram\t\t\t\tRank Ratio\n",
      "1\tp ibid\t\t\t8451.671\n",
      "2\tfigure figure\t\t\t4387.68\n",
      "3\tthe internet\t\t\t1655.15\n",
      "4\theat exchanger\t\t\t1424.038\n",
      "5\tthe companys\t\t\t1408.576\n",
      "6\texam performance\t\t\t1269.606\n",
      "7\tyoungs modulus\t\t\t1048.631\n",
      "8\ti dont\t\t\t993.778\n",
      "9\tbirthweight ratio\t\t\t836.958\n",
      "10\tchild soldiers\t\t\t833.248\n",
      "11\tthe bohr\t\t\t748.879\n",
      "12\tmanufacturing strategy\t\t\t734.568\n",
      "13\tottoman empire\t\t\t720.615\n",
      "14\tinduction motor\t\t\t704.328\n",
      "15\trate constant\t\t\t654.397\n",
      "16\thistory relevant\t\t\t646.073\n",
      "17\ttort law\t\t\t629.672\n",
      "18\tgenetically modified\t\t\t613.156\n",
      "19\tibid pp\t\t\t609.165\n",
      "20\tinternet and\t\t\t604.723\n",
      "21\tof womens\t\t\t584.58\n",
      "22\tyield management\t\t\t583.962\n",
      "23\tphonological processes\t\t\t582.317\n",
      "24\ttorrington et\t\t\t576.476\n",
      "25\temotional labour\t\t\t573.496\n",
      "26\topen source\t\t\t569.734\n",
      "27\tbased care\t\t\t557.345\n",
      "28\tthis essay\t\t\t552.337\n",
      "29\tthe wto\t\t\t534.324\n",
      "30\tassurance schemes\t\t\t524.805\n"
     ]
    }
   ],
   "source": [
    "#### [ TODO ] \n",
    "# sorted(iterable, cmp=None, key=None, reverse=False)\n",
    "# bi_rank_ratio is a dictionary \n",
    "print(f'rank\\tbigram\\t\\t\\t\\tRank Ratio')\n",
    "for i,ratio_set in enumerate(sorted(bi_rank_ratio.items(), key=lambda item: item[1],reverse=True)[:30]):\n",
    "    print(f'{i+1}\\t{ratio_set[0]}\\t\\t\\t{round(ratio_set[1],3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef-_B3bnx6py"
   },
   "source": [
    "## TA's Notes\n",
    "\n",
    "If you complete the Assignment, please use [this link](https://docs.google.com/spreadsheets/d/1OKbXhcv6E3FEQDPnbHEHEeHvpxv01jxugMP7WwnKqKw/edit#gid=0) to reserve demo time.  \n",
    "The score is only given after TAs review your implementation, so <u>**make sure you make a appointment with a TA before you miss the deadline**</u> .  <br>After demo, please upload your assignment to e-learn website. You just need to hand in this ipynb file and rename it as XXXXXXXXX(Your student ID).ipynb.\n",
    "<br>Note that **late submission will not be allowed**.  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
